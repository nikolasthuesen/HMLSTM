{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopi af Gustav_3L.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGhxUF1SmPcW",
        "colab_type": "text"
      },
      "source": [
        "Link til Hanqing Lu's github: https://github.com/HanqingLu/MultiscaleRNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRr388TrNp-T",
        "colab_type": "text"
      },
      "source": [
        "### Import packages and activate cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jODfPA2GJrDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, math, time, os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.autograd import Variable, Function\n",
        "from torch.nn import Module, Parameter\n",
        "from torch.nn.functional import softmax\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='once')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN3aYwGlrfh3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1-C_PfvNoma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34edcc91-2876-4f40-e945-aa4723a8eb1c"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print(\"Running GPU.\") if use_cuda else print(\"No GPU available.\")\n",
        "\n",
        "\n",
        "def get_variable(x):\n",
        "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
        "    if use_cuda:\n",
        "        return x.cuda()\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_numpy(x):\n",
        "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
        "    if use_cuda:\n",
        "        return x.cpu().data.numpy()\n",
        "    return x.data.numpy()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Qrlck8zNdCx",
        "colab_type": "text"
      },
      "source": [
        "### Small function and class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elybdMT8ppif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#A modification of the simoid function, as described in the article. a defines the slope hard_sigm(x) = max(0,min(1,(ax+1)/2))\n",
        "\n",
        "def hard_sigm(a, x):\n",
        "    temp = torch.div(torch.add(torch.mul(x, a), 1), 2.0)\n",
        "    output = torch.clamp(temp, min=0, max=1)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZNHyDOHLB7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class bound(Function):\n",
        "    def forward(self, x):\n",
        "        # forward : x -> output\n",
        "        self.save_for_backward(x)\n",
        "        output = x > 0.5\n",
        "        return output.float()\n",
        "\n",
        "    def backward(self, output_grad):\n",
        "        # backward: output_grad -> x_grad\n",
        "        x = self.saved_tensors\n",
        "        x_grad = None\n",
        "\n",
        "        if self.needs_input_grad[0]:\n",
        "            x_grad = output_grad.clone()\n",
        "\n",
        "        return x_grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acEILFS3LFyW",
        "colab_type": "text"
      },
      "source": [
        "## HM_LSTM network defined by 3 classes (CELL, HMLSTM AND HMLSTM NET)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY2dlvpuHltx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HM_LSTMCell(Module):\n",
        "    def __init__(self, bottom_size, hidden_size, top_size, a, last_layer):\n",
        "        super(HM_LSTMCell, self).__init__()\n",
        "        self.bottom_size = bottom_size\n",
        "        self.hidden_size = hidden_size \n",
        "        self.top_size = top_size\n",
        "        self.a = a #se slope annealing trick i training\n",
        "        self.last_layer = last_layer\n",
        "\n",
        "\n",
        "        #Initialize weight matrices for transition of hidden states between HM_LSTM cells\n",
        "        '''\n",
        "        U_recur means the state transition parameters from layer l (current layer) to layer l\n",
        "        U_topdown means the state transition parameters from layer l+1 (top layer) to layer l\n",
        "        W_bottomup means the state transition parameters from layer l-1 (bottom layer) to layer l\n",
        "        '''\n",
        "        self.W_bottomup = Parameter(torch.cuda.FloatTensor(4 * self.hidden_size + 1, self.bottom_size))\n",
        "        self.U_recur = Parameter(torch.cuda.FloatTensor(4 * self.hidden_size + 1, self.hidden_size))\n",
        "\n",
        "        if not self.last_layer:\n",
        "            self.U_topdown = Parameter(torch.cuda.FloatTensor(4 * self.hidden_size + 1, self.top_size))\n",
        "\n",
        "        self.bias = Parameter(torch.cuda.FloatTensor(4 * self.hidden_size + 1))\n",
        "\n",
        "        #Perform weight initialization of these 4 (or 3) parameters with function defined below.\n",
        "        self.reset_parameters()\n",
        "\n",
        "    #Think about redoing weight initialization: https://erwanscornet.github.io/teaching/RNN.pdf\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for par in self.parameters():\n",
        "            par.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, c, h_bottomup, h_recur, h_topdown, z, z_bottom): \n",
        "        # h_bottom.size = bottom_size * batch_size\n",
        "        \"\"\"\n",
        "        c:                  cell state in previous cell (l,t-1)\n",
        "        h_bottomup:         hidden states in layer below (l-1,t)\n",
        "        h_recur:            hidden states in previous timestep (l,t-1)\n",
        "        h_topdown:          hidden states in layer above and previous timestep (l+1,t-1)\n",
        "        z:                  boundary state in previous time step (l,t-1)\n",
        "        z_bottom:           boundary state in layer below (l-1,t)\n",
        "\n",
        "        \"\"\"\n",
        "        #Calculate s-matrices to calculate new cell state (COPY,UPDATE or FLUSH)\n",
        "        s_recur = torch.mm(self.U_recur, h_recur)\n",
        "        \n",
        "        s_bottomup_init = torch.mm(self.W_bottomup, h_bottomup)\n",
        "        s_bottomup = z_bottom.expand_as(s_bottomup_init) * s_bottomup_init\n",
        "\n",
        "        #If not last layer, calculate s_topdown, else set s_topdown to 0\n",
        "        if not self.last_layer:\n",
        "            s_topdown_init = torch.mm(self.U_topdown, h_topdown) \n",
        "            s_topdown = z.expand_as(s_topdown_init) * s_topdown_init\n",
        "        else:\n",
        "            s_topdown = Variable(torch.zeros(s_recur.size()).cuda(), requires_grad=False).cuda()\n",
        "\n",
        "\n",
        "        #Extract individual variables (matrix/vector) from the large S matrix (f_s: f_slice) \n",
        "        f_s = s_recur + s_topdown + s_bottomup + self.bias.unsqueeze(1).expand_as(s_recur)\n",
        "\n",
        "        # f_s.size = (4 * hidden_size + 1) * batch_size\n",
        "        f = torch.sigmoid(f_s[0:self.hidden_size, :])  # hidden_size * batch_size\n",
        "        i = torch.sigmoid(f_s[self.hidden_size:self.hidden_size*2, :])\n",
        "        o = torch.sigmoid(f_s[self.hidden_size*2:self.hidden_size*3, :])\n",
        "        g = torch.tanh(f_s[self.hidden_size*3:self.hidden_size*4, :])\n",
        "        z_hat = hard_sigm(self.a, f_s[self.hidden_size*4:self.hidden_size*4+1, :])\n",
        "\n",
        "        #Make vector of ones and resize the boundary states (z-values) to be the same size as the cell parameters (f, i, o and g) \n",
        "        one = Variable(torch.ones(f.size()).cuda(), requires_grad=False)\n",
        "        z = z.expand_as(f)\n",
        "        z_bottom = z_bottom.expand_as(f)\n",
        "\n",
        "        #Calculate cell state (one line implementation of out commented if/else below)\n",
        "        c_new = z * (i * g) + (one - z) * (one - z_bottom) * c + (one - z) * z_bottom * (f * c + i * g) #burde ikke beregnes for ethvert tilfælde? \n",
        "        h_new = z * o * torch.tanh(c_new) + (one - z) * (one - z_bottom) * h_recur + (one - z) * z_bottom * o * torch.tanh(c_new)\n",
        "\n",
        "        # if z == 1: (FLUSH)\n",
        "        #     c_new = i * g\n",
        "        #     h_new = o * Func.tanh(c_new)\n",
        "        # elif z_bottom == 0: (COPY)\n",
        "        #     c_new = c\n",
        "        #     h_new = h\n",
        "        # else: (UPDATE)\n",
        "        #     c_new = f * c + i * g\n",
        "        #     h_new = o * Func.tanh(c_new)\n",
        "\n",
        "        #Saves original x values: both 0, 1 and values in between (found using a), to be used in the backward pass. \n",
        "        #Hereafter sets x < 0.5 to 0 and x > 0.5 to 1 as they are used in the forward pass\n",
        "        z_new = bound()(z_hat)\n",
        "\n",
        "        return h_new, c_new, z_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkAV7YKQHm3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HM_LSTM(Module): #Istedet for at lave egen LSTM så brug den fra main.py\n",
        "    def __init__(self, a, input_size, size_list):\n",
        "        super(HM_LSTM, self).__init__()\n",
        "        self.a = a\n",
        "        self.input_size = input_size #bottom_size\n",
        "        self.size_list = size_list \n",
        "        \n",
        "        \"\"\"\n",
        "        input_size:        Input size to network\n",
        "        size_list[0]:      hidden size of layer 1 aka. input size after embedding\n",
        "        size_list[1]:      hidden size of layer 2\n",
        "        size_list[2]:      hidden size of layer 3\n",
        "        \"\"\"\n",
        "\n",
        "        #Init cell state\n",
        "        self.cell_1 = HM_LSTMCell(self.input_size, self.size_list[0], self.size_list[1], self.a, False) #bottom_size, hidden_size, top_size, a, last_layer\n",
        "        self.cell_2 = HM_LSTMCell(self.size_list[0], self.size_list[1], self.size_list[2], self.a, False)\n",
        "        self.cell_3 = HM_LSTMCell(self.size_list[1], self.size_list[2], None, self.a, True)\n",
        "\n",
        "    def forward(self, inputs, hidden): #hidden state supplied, if the model is going to freestyle or make predictions that dont start from 0\n",
        "        # inputs.size = (batch_size, time steps, embed_size/input_size) \n",
        "\n",
        "        time_steps = inputs.size(1)\n",
        "        batch_size = inputs.size(0)\n",
        "\n",
        "        if hidden == None:\n",
        "            #Layer 1\n",
        "            h_t1 = Variable(torch.zeros(self.size_list[0], batch_size).float().cuda(), requires_grad=False)\n",
        "            c_t1 = Variable(torch.zeros(self.size_list[0], batch_size).float().cuda(), requires_grad=False)\n",
        "            z_t1 = Variable(torch.zeros(1, batch_size).float().cuda(), requires_grad=False)\n",
        "            #Layer 2\n",
        "            h_t2 = Variable(torch.zeros(self.size_list[1], batch_size).float().cuda(), requires_grad=False)\n",
        "            c_t2 = Variable(torch.zeros(self.size_list[1], batch_size).float().cuda(), requires_grad=False)\n",
        "            z_t2 = Variable(torch.zeros(1, batch_size).float().cuda(), requires_grad=False)\n",
        "            #Layer 3\n",
        "            h_t3 = Variable(torch.zeros(self.size_list[2], batch_size).float().cuda(), requires_grad=False)\n",
        "            c_t3 = Variable(torch.zeros(self.size_list[2], batch_size).float().cuda(), requires_grad=False)\n",
        "            z_t3 = Variable(torch.zeros(1, batch_size).float().cuda(), requires_grad=False)\n",
        "        else:\n",
        "            (h_t1, c_t1, z_t1, h_t2, c_t2, z_t2, h_t3, c_t3, z_t3) = hidden\n",
        "\n",
        "        #Make vector of ones with the same size as batch, so that input is always passed via s_bottomup (see HMLSTMCell)\n",
        "        z_one = Variable(torch.ones(1, batch_size).float().cuda(), requires_grad=False)\n",
        "        \n",
        "        \"\"\"\n",
        "        h_t1:     hidden states of layer 1 at previous timestep (updates to current in each iteration)\n",
        "        h_t2:     hidden states of layer 2 at previous timestep (updates to current timestep in each iteration)\n",
        "        h_t3:     hidden states of layer 3 --||--\n",
        "        z_1:      boundary state of layer 1 --||--\n",
        "        z_2:      boundary state of layer 2 --||--\n",
        "        z_3:      boundary state of layer 3 --||--\n",
        "        \"\"\"\n",
        "\n",
        "        h_1, h_2, h_3, z_1, z_2, z_3 = [], [], [], [], [], [] \n",
        "\n",
        "\n",
        "        for t in range(time_steps):\n",
        "            h_t1, c_t1, z_t1 = self.cell_1(c=c_t1, h_bottomup=inputs[:,t, :].t(), h_recur=h_t1, h_topdown=h_t2, z=z_t1, z_bottom=z_one) #t1 og t2 is layer1 and layer2 and not time1 and time2\n",
        "            h_t2, c_t2, z_t2 = self.cell_2(c=c_t2, h_bottomup=h_t1, h_recur=h_t2, h_topdown=h_t3, z=z_t2, z_bottom=z_t1)  \n",
        "            h_t3, c_t3, z_t3 = self.cell_3(c=c_t3, h_bottomup=h_t2, h_recur=h_t3, h_topdown=None, z=z_t3, z_bottom=z_t2)  \n",
        "\n",
        "            h_1 += [h_t1.t()]\n",
        "            h_2 += [h_t2.t()]\n",
        "            h_3 += [h_t3.t()]\n",
        "            z_1 += [z_t1.t()]\n",
        "            z_2 += [z_t2.t()]\n",
        "            z_3 += [z_t2.t()]\n",
        "\n",
        "        hidden = (h_t1, c_t1, z_t1, h_t2, c_t2, z_t2, h_t3, c_t3, z_t3)\n",
        "        return torch.stack(h_1, dim=1), torch.stack(h_2, dim=1), torch.stack(h_3, dim=1), torch.stack(z_1, dim=1), torch.stack(z_2, dim=1), torch.stack(z_3, dim=1), hidden\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc2G--sAZoSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HM_Net(Module):\n",
        "    def __init__(self, a, size_list, dict_size, embed_size):\n",
        "        super(HM_Net, self).__init__()\n",
        "        self.dict_size = dict_size # Vocab size\n",
        "        self.size_list = size_list # Number of hidden units in each layer\n",
        "        self.embed_in = nn.Embedding(dict_size, embed_size) #dict_size, embed_size\n",
        "        self.HM_LSTM = HM_LSTM(a, embed_size, size_list)\n",
        "        self.weight = nn.Linear(size_list[0]+size_list[1]+size_list[2],3)\n",
        "        self.embed_out1 = nn.Linear(size_list[0], dict_size)\n",
        "        self.embed_out2 = nn.Linear(size_list[1], dict_size)\n",
        "        self.embed_out3 = nn.Linear(size_list[2], dict_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, inputs, target, hidden):\n",
        "        # inputs : batch_size * time_steps\n",
        "  \n",
        "        #Embedding\n",
        "        emb = self.embed_in(inputs)  # batch_size * time_steps * embed_size\n",
        "\n",
        "        #Initialize network and do forward pass\n",
        "        h_1, h_2, h_3, z_1, z_2, z_3, hidden = self.HM_LSTM(emb, hidden)  # batch_size * time_steps * hidden_size\n",
        "\n",
        "        h = torch.cat((h_1, h_2, h_3), 2) #Applied as a 3D tensor. \n",
        "\n",
        "\n",
        "        #Do FFNN throuch weights g1 and g2 to h_e which acts as predictor of x_(t+1). \n",
        "        #h: Dim: batch, seq len,  total units in hidden layer\n",
        "        g = torch.sigmoid(self.weight(h.view(h.size(0)*h.size(1), h.size(2)))) # This g is not the LSTM g, but the g combining the different hidden states to predict the outputs\n",
        "        g_1 = g[:, 0:1]  # batch_size * time_steps, 1\n",
        "        g_2 = g[:, 1:2]\n",
        "        g_3 = g[:, 2:3]\n",
        "\n",
        "        h_e1 = g_1.expand(g_1.size(0), self.dict_size)*self.embed_out1(h_1.view(h_1.size(0)*h_1.size(1), h_1.size(2)))  \n",
        "        h_e2 = g_2.expand(g_2.size(0), self.dict_size)*self.embed_out2(h_2.view(h_2.size(0)*h_2.size(1), h_2.size(2)))\n",
        "        h_e3 = g_3.expand(g_3.size(0), self.dict_size)*self.embed_out3(h_3.view(h_3.size(0)*h_3.size(1), h_3.size(2)))\n",
        "\n",
        "        h_e = self.relu(h_e1 + h_e2 + h_e3)  # batch_size*time_steps, hidden_size\n",
        "        output = h_e\n",
        "\n",
        "        batch_loss = self.loss(output, target) # Variable(target)\n",
        "\n",
        "        return batch_loss, hidden, output, z_1, z_2, z_3\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        #Layer 1\n",
        "        h_t1 = Variable(torch.zeros(self.size_list[0], batch_size).float().cuda(), requires_grad=False)\n",
        "        c_t1 = Variable(torch.zeros(self.size_list[0], batch_size).float().cuda(), requires_grad=False)\n",
        "        z_t1 = Variable(torch.zeros(1, batch_size).float().cuda(), requires_grad=False)\n",
        "        # Layer 2\n",
        "        h_t2 = Variable(torch.zeros(self.size_list[1], batch_size).float().cuda(), requires_grad=False)\n",
        "        c_t2 = Variable(torch.zeros(self.size_list[1], batch_size).float().cuda(), requires_grad=False)\n",
        "        z_t2 = Variable(torch.zeros(1, batch_size).float().cuda(), requires_grad=False)\n",
        "        # Layer 3\n",
        "        h_t3 = Variable(torch.zeros(self.size_list[2], batch_size).float().cuda(), requires_grad=False)\n",
        "        c_t3 = Variable(torch.zeros(self.size_list[2], batch_size).float().cuda(), requires_grad=False)\n",
        "        z_t3 = Variable(torch.zeros(1, batch_size).float().cuda(), requires_grad=False)\n",
        "\n",
        "        hidden = (h_t1, c_t1, z_t1, h_t2, c_t2, z_t2, h_t3, c_t3, z_t3 )\n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhlXubs4LW0A",
        "colab_type": "text"
      },
      "source": [
        "### Load data and activate cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFN-uXHkuXfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9acc54fc-9779-4795-eefe-4ec4032a6ab2"
      },
      "source": [
        "#Tokenizer: splits sentences into char tokens\n",
        "def tokenize(lines):\n",
        "    return [line for line in lines]\n",
        "\n",
        "# set up fields\n",
        "TEXT = data.Field(lower=True, tokenize=tokenize, batch_first=True)\n",
        "\n",
        "# make splits for data\n",
        "train, valid, test = datasets.PennTreebank.splits(TEXT)\n",
        "\n",
        "# print information about the data\n",
        "print('train.fields', train.fields)\n",
        "print('len(train)', len(train))\n",
        "print('vars(train[0])', vars(train[0])['text'][0:10])\n",
        "\n",
        "# build the vocabulary\n",
        "TEXT.build_vocab(train) # Try with random initialization\n",
        "\n",
        "# print vocab information\n",
        "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
        "\n",
        "# make iterator for splits\n",
        "train_iter, valid_iter, test_iter = data.BPTTIterator.splits(\n",
        "    (train, valid, test), batch_size=64, bptt_len=100, device=\"cuda:0\")\n",
        "\n",
        "# print batch information\n",
        "batch = next(iter(train_iter))\n",
        "#print(batch.text)\n",
        "#print(batch.target)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.fields {'text': <torchtext.data.field.Field object at 0x7f20d7d0b7b8>}\n",
            "len(train) 1\n",
            "vars(train[0]) [' ', 'a', 'e', 'r', ' ', 'b', 'a', 'n', 'k', 'n']\n",
            "len(TEXT.vocab) 51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsIY3PzVLrhD",
        "colab_type": "text"
      },
      "source": [
        "### Initialization of hyperparameters for training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtH8-gWKazHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_params = locals().copy()\n",
        "\n",
        "train_data = train_iter\n",
        "val_data = valid_iter\n",
        "test_data = test_iter\n",
        "dict_size = len(TEXT.vocab) #len(corpus.dictionary) # vocab_size \n",
        "model_params['dict_size'] = dict_size\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 4\n",
        "\n",
        "#size_list = [hidden size of layer 1, hidden size of layer 2]\n",
        "size_list = [256, 256, 256] \n",
        "embed_size = 128\n",
        "model = HM_Net(1.0, size_list, dict_size, embed_size) # size_list = Number of hidden units in each layer a = 1.0\n",
        "model = model.cuda()\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate) \n",
        "\n",
        "# Add learning rate decay\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.8)\n",
        "\n",
        "it = 0\n",
        "start_time = time.time()\n",
        "bestPPL = 100000\n",
        "break_flag = False\n",
        "batch_size=64\n",
        "\n",
        "#indsat 25. november:\n",
        "clip=1\n",
        "\n",
        "# Track loss\n",
        "training_loss, validation_loss = [], []\n",
        "loss_list = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O8f4BpFPa01",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQVaYZ1h69Us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b2db38b0-75af-42a6-b3a8-ac10d00e92ed"
      },
      "source": [
        "# Track loss\n",
        "training_loss, validation_loss = [], []\n",
        "loss_list = []\n",
        "\n",
        "print('Starting model with following parameters:')\n",
        "print('Embed dim:', embed_size)\n",
        "print('Hidden dim:', size_list)\n",
        "\n",
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"start training epoch \", str(epoch+1), 'with learning rate:', scheduler.get_lr())\n",
        "\n",
        "    hidden_init = model.init_hidden(batch_size)\n",
        "\n",
        "    # Track loss\n",
        "    epoch_training_loss = 0\n",
        "    epoch_validation_loss = 0\n",
        "    i = 0\n",
        "    model.eval()\n",
        "        \n",
        "    # For each sentence in validation set\n",
        "    print('Starting validation data')\n",
        "    for batch in val_data:\n",
        "\n",
        "        hidden = hidden_init\n",
        "\n",
        "        inputs = batch.text\n",
        "        inputs = inputs.T\n",
        "\n",
        "        target = batch.target\n",
        "        target = target.T\n",
        "        target = target.reshape(-1)\n",
        "        \n",
        "        # Forward pass\n",
        "        loss, hidden, output, z1, z2, z3 = model(inputs, target, hidden)\n",
        "        \n",
        "        # Update loss\n",
        "        epoch_validation_loss += loss.detach().cpu().data.numpy()\n",
        "\n",
        "        #evt. hvis memory stadigvæk bliver fyldt\n",
        "        #del target, del hidden, del loss\n",
        "\n",
        "    model.train()\n",
        "    i = 0\n",
        "    for batch in train_data:\n",
        "        i += 1\n",
        "        if i%100 == 0:\n",
        "            print(i,\"Train\")\n",
        "\n",
        "        hidden = hidden_init\n",
        "        \n",
        "        optimizer.zero_grad()  # 0.0001s used\n",
        "\n",
        "        inputs = batch.text\n",
        "        inputs = inputs.T\n",
        "\n",
        "        target = batch.target\n",
        "        target = target.T\n",
        "        target = target.reshape(-1)\n",
        "               \n",
        "        loss, hidden, output, z1, z2, z3 = model(inputs, target, hidden) #tager til forward (inputs, target, hidden)\n",
        "        loss.backward()  # 3s used\n",
        "        nn.utils.clip_grad_norm(model.parameters(), clip)\n",
        "        optimizer.step()  # 0.001s used\n",
        "\n",
        "\n",
        "        # Update loss\n",
        "        epoch_training_loss += loss.detach().cpu().data.numpy()\n",
        "        \n",
        "        #evt. hvis memory stadigvæk bliver fyldt\n",
        "        #del target, del hidden, del loss\n",
        "\n",
        "    # slope annealing trick\n",
        "    scheduler.step()\n",
        "    model.HM_LSTM.cell_1.a += 0.04\n",
        "    model.HM_LSTM.cell_2.a += 0.04\n",
        "    print(\"--------annealing slope a to\", model.HM_LSTM.cell_1.a)\n",
        "    print('Epoch: ', epoch+1, 'finished. Time elapsed:', (time.time() - start_time)/60, 'minutes')\n",
        "    print('training loss:', epoch_training_loss / len(train_data))\n",
        "    print('validation loss:', epoch_validation_loss / len(val_data))\n",
        "\n",
        "    # Save loss for plot\n",
        "    training_loss.append(epoch_training_loss / len(train_data))\n",
        "    validation_loss.append(epoch_validation_loss / len(val_data))\n",
        "\n",
        "\n",
        "# Plot training and validation loss of training and validation batches\n",
        "epoch = np.arange(len(training_loss))\n",
        "plt.figure()\n",
        "plt.plot(epoch, training_loss, 'r', label='Training loss',)\n",
        "plt.plot(epoch, validation_loss, 'b', label='Validation loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch'), plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting model with following parameters:\n",
            "Embed dim: 128\n",
            "Hidden dim: [256, 256, 256]\n",
            "start training epoch  1 with learning rate: [0.01]\n",
            "Starting validation data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "100 Train\n",
            "200 Train\n",
            "300 Train\n",
            "400 Train\n",
            "500 Train\n",
            "600 Train\n",
            "700 Train\n",
            "--------annealing slope a to 1.2000000000000002\n",
            "Epoch:  1 finished. Time elapsed: 77.9268626968066 minutes\n",
            "training loss: 1.2489799438861378\n",
            "validation loss: 1.293416182200114\n",
            "start training epoch  2 with learning rate: [0.008]\n",
            "Starting validation data\n",
            "100 Train\n",
            "200 Train\n",
            "300 Train\n",
            "400 Train\n",
            "500 Train\n",
            "600 Train\n",
            "700 Train\n",
            "--------annealing slope a to 1.2400000000000002\n",
            "Epoch:  2 finished. Time elapsed: 93.63988607724508 minutes\n",
            "training loss: 1.2181413473939537\n",
            "validation loss: 1.2740598633175804\n",
            "start training epoch  3 with learning rate: [0.008]\n",
            "Starting validation data\n",
            "100 Train\n",
            "200 Train\n",
            "300 Train\n",
            "400 Train\n",
            "500 Train\n",
            "600 Train\n",
            "700 Train\n",
            "--------annealing slope a to 1.2800000000000002\n",
            "Epoch:  3 finished. Time elapsed: 109.36534119049708 minutes\n",
            "training loss: 1.2068926034714644\n",
            "validation loss: 1.2500217831324016\n",
            "start training epoch  4 with learning rate: [0.008]\n",
            "Starting validation data\n",
            "100 Train\n",
            "200 Train\n",
            "300 Train\n",
            "400 Train\n",
            "500 Train\n",
            "600 Train\n",
            "700 Train\n",
            "--------annealing slope a to 1.3200000000000003\n",
            "Epoch:  4 finished. Time elapsed: 125.06094532807668 minutes\n",
            "training loss: 1.2045293719248664\n",
            "validation loss: 1.2432243880771456\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJKz/B8D4lBbowqhbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdTH_m_2hMgs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f289faee-9225-48f4-9dec-8182da720899"
      },
      "source": [
        "  \n",
        "# Get first sentence in test set\n",
        "loss_list = []\n",
        "BPC_list = []\n",
        "j=0\n",
        "total_loss = 0\n",
        "it = 0\n",
        "\n",
        "for batch in test_data:\n",
        "    hidden = hidden_init\n",
        "\n",
        "    inputs = batch.text.T\n",
        "    target = batch.target.T\n",
        "    target = target.reshape(-1)\n",
        "\n",
        "    loss, hidden, output, z1, z2, z3 = model.forward(inputs, target, hidden)  \n",
        "    \n",
        "    total_loss += loss.detach().cpu().data.numpy() #tester lige \n",
        "    it += 1\n",
        "\n",
        "    loss_list.append(loss.detach().cpu().data.numpy())\n",
        "\n",
        "    target_array = target.cpu().data.numpy()\n",
        "    # Bad way of doing BPC\n",
        "    #outputs_softmax = softmax(output) #BPC kræver log2 og pytorchs softmax bruger den naturlige log. Derfor kan man ikke tage mean af cross entropy\n",
        "    \n",
        "    #output_softmax_array = outputs_softmax.cpu().data.numpy()\n",
        "    \n",
        "    #summation = 0\n",
        "    #for i in range(0,len(target_array)):\n",
        "    #    prob_of_true = output_softmax_array[i][target_array[i]]\n",
        "    #    summation += np.log2(prob_of_true)\n",
        "    #BPC_list.append(- 1 / len(target_array) * summation)\n",
        "    j += 1\n",
        "    if j == 70:\n",
        "        break\n",
        "\n",
        "print('mean of BPC:', np.mean(loss_list/np.log(2)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mean of BPC: 1.8167461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d9RdE_2ciig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6f175fc0-83d2-4212-89fd-fdc86dbe79f0"
      },
      "source": [
        "# Prediction\n",
        "z1_array = z1.view(-1, 100*64)\n",
        "z1_array = z1_array.cpu().data.numpy()\n",
        "\n",
        "z2_array = z2.view(-1, 64*100)\n",
        "z2_array = z2_array.cpu().data.numpy()\n",
        "\n",
        "z3_array = z3.view(-1, 64*100)\n",
        "z3_array = z3_array.cpu().data.numpy()\n",
        "\n",
        "l1_state, l2_state, l3_state = 'EMPTY', 'EMPTY', 'EMPTY'\n",
        "\n",
        "output_array = output.cpu().data.numpy()\n",
        "for i in range(0,200,1):\n",
        "    #predict\n",
        "    char_vector = output_array[i]\n",
        "    char = np.argmax(char_vector)\n",
        "    predict_char = TEXT.vocab.itos[char]\n",
        "\n",
        "    # True\n",
        "    char = target_array[i]\n",
        "    true_char = TEXT.vocab.itos[char]\n",
        "\n",
        "    if i > 0:\n",
        "      # layer 1\n",
        "      if z1_array[0, i-1] == 1:\n",
        "        l1_state = 'FLUSH' # Flush\n",
        "      else:\n",
        "        l1_state = 'UPDATE' # update\n",
        "\n",
        "      # Layer 2\n",
        "      if z2_array[0, i-1] == 1:\n",
        "        l2_state = 'FLUSH' # Flush\n",
        "      elif z2_array[0, i-1] == 0 and z1_array[0, i] == 0:\n",
        "        l2_state = 'COPY' # Copy\n",
        "      elif z2_array[0, i-1] == 0 and z1_array[0, i] == 1:\n",
        "        l2_state = 'UPDATE' # update\n",
        "      \n",
        "      # Layer 3\n",
        "      if z3_array[0, i-1] == 1:\n",
        "        l3_state = 'FLUSH' # Flush\n",
        "      elif z3_array[0, i-1] == 0 and z2_array[0, i] == 0:\n",
        "        l3_state = 'COPY' # Copy\n",
        "      elif z3_array[0, i-1] == 0 and z2_array[0, i] == 1:\n",
        "        l3_state = 'UPDATE' # update\n",
        "    \n",
        "    print(true_char, predict_char, l1_state, l2_state, l3_state, sep='\\t')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n\tn\tEMPTY\tEMPTY\tEMPTY\n",
            "g\tg\tUPDATE\tCOPY\tCOPY\n",
            "i\t \tUPDATE\tCOPY\tCOPY\n",
            "n\tn\tUPDATE\tCOPY\tCOPY\n",
            "g\tg\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "t\tt\tUPDATE\tCOPY\tCOPY\n",
            "h\th\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            "i\t \tUPDATE\tCOPY\tCOPY\n",
            "r\tr\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "b\tc\tUPDATE\tCOPY\tCOPY\n",
            "r\tu\tUPDATE\tCOPY\tCOPY\n",
            "o\ti\tUPDATE\tCOPY\tCOPY\n",
            "k\tt\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            "r\tr\tUPDATE\tCOPY\tCOPY\n",
            "s\ta\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "w\ta\tUPDATE\tCOPY\tCOPY\n",
            "o\ti\tUPDATE\tCOPY\tCOPY\n",
            "n\tu\tUPDATE\tCOPY\tCOPY\n",
            "d\td\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            "r\tr\tUPDATE\tCOPY\tCOPY\n",
            "i\t \tUPDATE\tCOPY\tCOPY\n",
            "n\tn\tUPDATE\tCOPY\tCOPY\n",
            "g\tg\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "w\tt\tUPDATE\tCOPY\tCOPY\n",
            "h\ti\tUPDATE\tCOPY\tCOPY\n",
            "e\ti\tUPDATE\tCOPY\tCOPY\n",
            "t\tn\tUPDATE\tCOPY\tCOPY\n",
            "h\th\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            "r\tr\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "a\tt\tUPDATE\tCOPY\tCOPY\n",
            "n\t \tUPDATE\tCOPY\tCOPY\n",
            "o\t \tUPDATE\tCOPY\tCOPY\n",
            "t\tt\tUPDATE\tCOPY\tCOPY\n",
            "h\th\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            "r\tr\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "c\tp\tUPDATE\tCOPY\tCOPY\n",
            "r\to\tUPDATE\tCOPY\tCOPY\n",
            "a\ti\tUPDATE\tCOPY\tCOPY\n",
            "s\ts\tUPDATE\tCOPY\tCOPY\n",
            "h\th\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "h\ta\tUPDATE\tCOPY\tCOPY\n",
            "a\ta\tUPDATE\tCOPY\tCOPY\n",
            "d\ts\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "b\ta\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            "g\te\tUPDATE\tCOPY\tCOPY\n",
            "u\ti\tUPDATE\tCOPY\tCOPY\n",
            "n\tn\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "<eos>\ta\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "a\tt\tUPDATE\tCOPY\tCOPY\n",
            "t\t \tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "p\tt\tUPDATE\tCOPY\tCOPY\n",
            "r\tr\tUPDATE\tCOPY\tCOPY\n",
            "u\to\tUPDATE\tCOPY\tCOPY\n",
            "d\td\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            "n\tn\tUPDATE\tCOPY\tCOPY\n",
            "t\tt\tUPDATE\tCOPY\tCOPY\n",
            "i\t \tUPDATE\tCOPY\tCOPY\n",
            "a\ta\tUPDATE\tCOPY\tCOPY\n",
            "l\tl\tUPDATE\tCOPY\tCOPY\n",
            "-\t \tUPDATE\tCOPY\tCOPY\n",
            "b\ts\tUPDATE\tCOPY\tCOPY\n",
            "a\ta\tUPDATE\tCOPY\tCOPY\n",
            "c\tc\tUPDATE\tCOPY\tCOPY\n",
            "h\th\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "s\ta\tUPDATE\tCOPY\tCOPY\n",
            "e\ta\tUPDATE\tCOPY\tCOPY\n",
            "c\tc\tUPDATE\tCOPY\tCOPY\n",
            "u\tu\tUPDATE\tCOPY\tCOPY\n",
            "r\tr\tUPDATE\tCOPY\tCOPY\n",
            "i\ti\tUPDATE\tCOPY\tCOPY\n",
            "t\tt\tUPDATE\tCOPY\tCOPY\n",
            "i\ti\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            "s\ts\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "i\ta\tUPDATE\tCOPY\tCOPY\n",
            "n\tn\tUPDATE\tCOPY\tCOPY\n",
            "c\t \tUPDATE\tCOPY\tCOPY\n",
            ".\t.\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "r\t \tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "t\tt\tUPDATE\tCOPY\tCOPY\n",
            "h\th\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "d\tc\tUPDATE\tCOPY\tCOPY\n",
            "i\te\tUPDATE\tCOPY\tCOPY\n",
            "r\ts\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            "c\tc\tUPDATE\tCOPY\tCOPY\n",
            "t\tt\tUPDATE\tCOPY\tCOPY\n",
            "i\to\tUPDATE\tCOPY\tCOPY\n",
            "o\to\tUPDATE\tCOPY\tCOPY\n",
            "n\tn\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "o\to\tUPDATE\tCOPY\tCOPY\n",
            "f\tf\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "t\tt\tUPDATE\tCOPY\tCOPY\n",
            "h\th\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "c\tc\tUPDATE\tCOPY\tCOPY\n",
            "o\to\tUPDATE\tCOPY\tCOPY\n",
            "m\tm\tUPDATE\tCOPY\tCOPY\n",
            "p\tp\tUPDATE\tCOPY\tCOPY\n",
            "a\ta\tUPDATE\tCOPY\tCOPY\n",
            "n\tn\tUPDATE\tCOPY\tCOPY\n",
            "y\ty\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "a\ta\tUPDATE\tCOPY\tCOPY\n",
            "n\ts\tUPDATE\tCOPY\tCOPY\n",
            "d\td\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "m\tt\tUPDATE\tCOPY\tCOPY\n",
            "r\ta\tUPDATE\tCOPY\tCOPY\n",
            ".\t.\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "s\t<\tUPDATE\tCOPY\tCOPY\n",
            "i\ta\tUPDATE\tCOPY\tCOPY\n",
            "m\tm\tUPDATE\tCOPY\tCOPY\n",
            "p\ti\tUPDATE\tCOPY\tCOPY\n",
            "s\tl\tUPDATE\tCOPY\tCOPY\n",
            "o\to\tUPDATE\tCOPY\tCOPY\n",
            "n\tn\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "s\ta\tUPDATE\tCOPY\tCOPY\n",
            "a\ta\tUPDATE\tCOPY\tCOPY\n",
            "i\tl\tUPDATE\tCOPY\tCOPY\n",
            "d\td\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "h\tt\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "r\ts\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            "s\tp\tUPDATE\tCOPY\tCOPY\n",
            "i\te\tUPDATE\tCOPY\tCOPY\n",
            "g\ts\tUPDATE\tCOPY\tCOPY\n",
            "n\tn\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            "d\td\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "i\tt\tUPDATE\tCOPY\tCOPY\n",
            "n\tn\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "n\tt\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "<eos>\t<eos>\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "s\tt\tUPDATE\tCOPY\tCOPY\n",
            "i\th\tUPDATE\tCOPY\tCOPY\n",
            "n\tn\tUPDATE\tCOPY\tCOPY\n",
            "c\tc\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "t\tt\tUPDATE\tCOPY\tCOPY\n",
            "h\th\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            "n\t \tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "h\ta\tUPDATE\tCOPY\tCOPY\n",
            "o\ta\tUPDATE\tCOPY\tCOPY\n",
            "o\tu\tUPDATE\tCOPY\tCOPY\n",
            "k\tl\tUPDATE\tCOPY\tCOPY\n",
            "e\te\tUPDATE\tCOPY\tCOPY\n",
            "r\ts\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "c\tt\tUPDATE\tCOPY\tCOPY\n",
            "o\to\tUPDATE\tCOPY\tCOPY\n",
            "r\tm\tUPDATE\tCOPY\tCOPY\n",
            "p\tp\tUPDATE\tCOPY\tCOPY\n",
            ".\t.\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "h\ta\tUPDATE\tCOPY\tCOPY\n",
            "a\ta\tUPDATE\tCOPY\tCOPY\n",
            "s\ts\tUPDATE\tCOPY\tCOPY\n",
            " \t \tUPDATE\tCOPY\tCOPY\n",
            "s\ta\tUPDATE\tCOPY\tCOPY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SNQEOLKln2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f9a20f0d-ae69-41cc-b62a-ac14f0e2a8de"
      },
      "source": [
        "# Generation of text\n",
        "\n",
        "# Convert text to numeric input\n",
        "input_text = 'new'\n",
        "input_text = list(input_text)\n",
        "\n",
        "text_numeric = []\n",
        "\n",
        "for char in input_text:\n",
        "  text_numeric.append(TEXT.vocab.stoi[char])\n",
        "\n",
        "\n",
        "# Run through model\n",
        "num_generations = 100\n",
        "input_array = np.array(text_numeric)\n",
        "\n",
        "hidden_init = model.init_hidden(1)\n",
        "hidden = hidden_init\n",
        "\n",
        "exp_dim = len(input_array)\n",
        "\n",
        "input_tensor = torch.from_numpy(input_array)\n",
        "input_tensor = input_tensor.expand(1,exp_dim)\n",
        "input_tensor = input_tensor.view(exp_dim,-1)\n",
        "input_tensor = input_tensor.T\n",
        "input_tensor = input_tensor.cuda()\n",
        "\n",
        "target_tensor = torch.ones(exp_dim).long().cuda()\n",
        "loss, hidden, outputs, z1, z2, z3 = model.forward(input_tensor,target_tensor, hidden)\n",
        "\n",
        "values, indices = outputs[-1].max(0)\n",
        "\n",
        "input_array = np.append(input_array, indices.cpu().numpy())\n",
        "\n",
        "for i in range(num_generations):\n",
        "  hidden_init = model.init_hidden(1)\n",
        "  hidden = hidden_init\n",
        "  exp_dim = len(input_array)\n",
        "  input_tensor = torch.from_numpy(input_array)\n",
        "  input_tensor = input_tensor.expand(1,exp_dim)\n",
        "  input_tensor = input_tensor.view(exp_dim,-1)\n",
        "  input_tensor = input_tensor.T\n",
        "  input_tensor = input_tensor.cuda()\n",
        "  target_tensor = torch.ones(exp_dim).long().cuda()\n",
        "  loss, hidden, outputs, z1, z2, z3 = model.forward(input_tensor,target_tensor, hidden)\n",
        "\n",
        "  values, indices = outputs[-1].max(0)\n",
        "\n",
        "  input_array = np.append(input_array, indices.cpu().numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/torch/csrc/autograd/python_function.cpp:622: UserWarning: Legacy autograd function with non-static forward method is deprecated and will be removed in 1.3. Please use new-style autograd function with static forward method. (Example: https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV3N4kIKo722",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae7470ee-29be-4a7a-c2fa-02885c267485"
      },
      "source": [
        "predicted_sentence = list() \n",
        "for char in input_array:\n",
        "  predict_char = TEXT.vocab.itos[char]\n",
        "  predicted_sentence.append(predict_char)\n",
        "\n",
        "print(''.join(predicted_sentence))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "new a <unk> and the company as a <unk> and the company as a <unk> and the company as a <unk> and the com\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQPW31yirQYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}